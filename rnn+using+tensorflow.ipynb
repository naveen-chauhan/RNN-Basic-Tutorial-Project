{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "import random \n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path='C:\\\\Users\\\\naveen chauhan\\\\Desktop\\\\mldata\\\\mlp\\\\RNN tensoflow\\\\'\n",
    "def read_data(file_name):\n",
    "    lines=open(file_name,'r')\n",
    "    content=lines.readlines()\n",
    "    content=[x.strip() for x in content]\n",
    "    content=[word for i in range(len(content)) for word in content[i].split()]\n",
    "    content=np.array(content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"belling_the_cat.txt\"\n",
    "training_data=read_data(logs_path+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now build the real dataset\n",
    "def build_dataset(data):\n",
    "    count=collections.Counter(data).most_common()\n",
    "    dictionary=dict()\n",
    "    for cnt,_ in count:\n",
    "        dictionary[cnt]=len(dictionary)\n",
    "    #reverse dictionary\n",
    "    reverse_dictionary=dict(zip(dictionary.values(),dictionary.keys()))\n",
    "    return dictionary,reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary,reverse_dictionary=build_dataset(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now initialize all tensorflow variable \n",
    "n_input=3\n",
    "n_hidden=512\n",
    "vocab_size=len(dictionary)\n",
    "\n",
    "x=tf.placeholder(tf.float32,[None,n_input,1])\n",
    "y=tf.placeholder(tf.float32,[None,vocab_size])\n",
    "\n",
    "training_iters=50000\n",
    "display_step=1000\n",
    "learning_rate=0.001\n",
    "\n",
    "weights={\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden,vocab_size]))\n",
    "}\n",
    "biases={\n",
    "    'out':tf.Variable(tf.random_normal([vocab_size]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we have defined all variables ,hence we define rnn function to train on model\n",
    "def RNN(x,weights,biases):\n",
    "    x=tf.reshape(x,[-1,n_input])\n",
    "    x=tf.split(x,n_input,1)\n",
    "    \n",
    "    #now we train\n",
    "    rnn_cell=rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n",
    "    \n",
    "    outputs,states=rnn.static_rnn(rnn_cell,x,dtype=tf.float32)\n",
    "    return tf.matmul(outputs[-1],weights['out'])+biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=RNN(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred,labels=y))\n",
    "optimizer=tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred=tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 1000, Average Loss= 4.335814, Average Accuracy= 6.90%\n",
      "['bell', 'the', 'cat'] - [?] vs [.]\n",
      "Iter= 2000, Average Loss= 2.950046, Average Accuracy= 19.00%\n",
      "['said', 'that', 'is'] - [all] vs [by]\n",
      "Iter= 3000, Average Loss= 2.443958, Average Accuracy= 33.60%\n",
      "['proposal', 'met', 'with'] - [general] vs [,]\n",
      "Iter= 4000, Average Loss= 2.171529, Average Accuracy= 45.50%\n",
      "['and', 'could', 'easily'] - [retire] vs [had]\n",
      "Iter= 5000, Average Loss= 2.013835, Average Accuracy= 49.40%\n",
      "['.', 'by', 'this'] - [means] vs [said]\n",
      "Iter= 6000, Average Loss= 1.681325, Average Accuracy= 55.90%\n",
      "['venture', ',', 'therefore'] - [,] vs [we]\n",
      "Iter= 7000, Average Loss= 1.406817, Average Accuracy= 63.70%\n",
      "['her', 'approach', ','] - [we] vs [we]\n",
      "Iter= 8000, Average Loss= 1.165792, Average Accuracy= 68.80%\n",
      "['and', 'treacherous', 'manner'] - [in] vs [all]\n",
      "Iter= 9000, Average Loss= 1.063496, Average Accuracy= 72.00%\n",
      "['agree', ',', 'said'] - [he] vs [he]\n",
      "Iter= 10000, Average Loss= 1.125618, Average Accuracy= 68.00%\n",
      "['he', 'thought', 'would'] - [meet] vs [meet]\n",
      "Iter= 11000, Average Loss= 0.943719, Average Accuracy= 74.50%\n",
      "['some', 'said', 'this'] - [,] vs [,]\n",
      "Iter= 12000, Average Loss= 1.025769, Average Accuracy= 73.90%\n",
      "['what', 'measures', 'they'] - [could] vs [they]\n",
      "Iter= 13000, Average Loss= 0.870986, Average Accuracy= 78.00%\n",
      "['it', 'is', 'easy'] - [to] vs [to]\n",
      "Iter= 14000, Average Loss= 0.784774, Average Accuracy= 79.10%\n",
      "['to', 'bell', 'the'] - [cat] vs [cat]\n",
      "Iter= 15000, Average Loss= 0.853898, Average Accuracy= 78.80%\n",
      "['general', 'applause', ','] - [until] vs [until]\n",
      "Iter= 16000, Average Loss= 0.776703, Average Accuracy= 82.30%\n",
      "['know', 'when', 'she'] - [was] vs [was]\n",
      "Iter= 17000, Average Loss= 0.689922, Average Accuracy= 81.60%\n",
      "['neck', 'of', 'the'] - [cat] vs [cat]\n",
      "Iter= 18000, Average Loss= 0.719620, Average Accuracy= 81.10%\n",
      "['therefore', ',', 'to'] - [propose] vs [propose]\n",
      "Iter= 19000, Average Loss= 0.755920, Average Accuracy= 81.80%\n",
      "['we', 'could', 'easily'] - [escape] vs [escape]\n",
      "Iter= 20000, Average Loss= 0.708889, Average Accuracy= 83.60%\n",
      "['the', 'sly', 'and'] - [treacherous] vs [treacherous]\n",
      "Iter= 21000, Average Loss= 0.654144, Average Accuracy= 83.90%\n",
      "['agree', ',', 'said'] - [he] vs [he]\n",
      "Iter= 22000, Average Loss= 0.722669, Average Accuracy= 82.80%\n",
      "['thought', 'would', 'meet'] - [the] vs [the]\n",
      "Iter= 23000, Average Loss= 0.630475, Average Accuracy= 85.50%\n",
      "['at', 'last', 'a'] - [young] vs [young]\n",
      "Iter= 24000, Average Loss= 0.518008, Average Accuracy= 87.20%\n",
      "['they', 'could', 'take'] - [to] vs [to]\n",
      "Iter= 25000, Average Loss= 0.575902, Average Accuracy= 85.00%\n",
      "['mouse', 'said', 'it'] - [is] vs [is]\n",
      "Iter= 26000, Average Loss= 0.599449, Average Accuracy= 85.40%\n",
      "['cat', '?', 'the'] - [mice] vs [mice]\n",
      "Iter= 27000, Average Loss= 0.644007, Average Accuracy= 84.30%\n",
      "['to', 'bell', 'the'] - [cat] vs [cat]\n",
      "Iter= 28000, Average Loss= 0.712351, Average Accuracy= 84.50%\n",
      "['old', 'mouse', 'got'] - [up] vs [up]\n",
      "Iter= 29000, Average Loss= 0.643957, Average Accuracy= 84.30%\n",
      "['she', 'was', 'in'] - [the] vs [the]\n",
      "Iter= 30000, Average Loss= 0.596099, Average Accuracy= 84.70%\n",
      "['easily', 'retire', 'while'] - [she] vs [.]\n",
      "Iter= 31000, Average Loss= 0.726456, Average Accuracy= 83.20%\n",
      "['when', 'she', 'was'] - [about] vs [about]\n",
      "Iter= 32000, Average Loss= 0.437428, Average Accuracy= 88.40%\n",
      "['and', 'attached', 'by'] - [a] vs [a]\n",
      "Iter= 33000, Average Loss= 0.608147, Average Accuracy= 85.30%\n",
      "['to', 'propose', 'that'] - [a] vs [a]\n",
      "Iter= 34000, Average Loss= 0.573849, Average Accuracy= 86.30%\n",
      "['we', 'could', 'easily'] - [escape] vs [escape]\n",
      "Iter= 35000, Average Loss= 0.524325, Average Accuracy= 87.70%\n",
      "['approaches', 'us', '.'] - [now] vs [now]\n",
      "Iter= 36000, Average Loss= 0.581014, Average Accuracy= 87.00%\n",
      "['the', 'sly', 'and'] - [treacherous] vs [treacherous]\n",
      "Iter= 37000, Average Loss= 0.419098, Average Accuracy= 90.20%\n",
      "['a', 'young', 'mouse'] - [got] vs [got]\n",
      "Iter= 38000, Average Loss= 0.475844, Average Accuracy= 89.50%\n",
      "['measures', 'they', 'could'] - [take] vs [take]\n",
      "Iter= 39000, Average Loss= 0.496799, Average Accuracy= 89.60%\n",
      "['propose', 'impossible', 'remedies'] - [.] vs [.]\n",
      "Iter= 40000, Average Loss= 0.568435, Average Accuracy= 87.20%\n",
      "['then', 'the', 'old'] - [mouse] vs [mouse]\n",
      "Iter= 41000, Average Loss= 0.611387, Average Accuracy= 87.00%\n",
      "['cat', '?', 'the'] - [mice] vs [mice]\n",
      "Iter= 42000, Average Loss= 0.564414, Average Accuracy= 87.70%\n",
      "['very', 'well', ','] - [but] vs [but]\n",
      "Iter= 43000, Average Loss= 0.625873, Average Accuracy= 87.50%\n",
      "['an', 'old', 'mouse'] - [got] vs [got]\n",
      "Iter= 44000, Average Loss= 0.474987, Average Accuracy= 88.90%\n",
      "['could', 'easily', 'retire'] - [while] vs [while]\n",
      "Iter= 45000, Average Loss= 0.470451, Average Accuracy= 88.00%\n",
      "['when', 'she', 'was'] - [about] vs [about]\n",
      "Iter= 46000, Average Loss= 0.463790, Average Accuracy= 88.90%\n",
      "[',', 'and', 'attached'] - [by] vs [by]\n",
      "Iter= 47000, Average Loss= 0.427195, Average Accuracy= 89.00%\n",
      "['a', 'small', 'bell'] - [be] vs [be]\n",
      "Iter= 48000, Average Loss= 0.400362, Average Accuracy= 91.40%\n",
      "['signal', 'of', 'her'] - [approach] vs [approach]\n",
      "Iter= 49000, Average Loss= 0.431164, Average Accuracy= 88.10%\n",
      "['manner', 'in', 'which'] - [the] vs [the]\n",
      "Iter= 50000, Average Loss= 0.537269, Average Accuracy= 88.20%\n",
      "['danger', 'consists', 'in'] - [the] vs [the]\n"
     ]
    }
   ],
   "source": [
    "#now start the session and do all the stuff\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    step=0\n",
    "    off_set=random.randint(0,n_input+1)\n",
    "    end_offset=n_input+1\n",
    "    acc_total=0\n",
    "    loss_total=0\n",
    "    while step<training_iters:\n",
    "        if off_set> (len(training_data)-end_offset):\n",
    "            off_set=random.randint(0,n_input+1)\n",
    "        symbols_in_keys=[dictionary[str(training_data[i])] for i in range(off_set,off_set+n_input)]\n",
    "        symbols_in_keys=np.reshape(symbols_in_keys,[-1,n_input,1])\n",
    "        symbols_out_onehot=np.zeros([vocab_size],dtype=float)\n",
    "        symbols_out_onehot[dictionary[str(training_data[off_set+n_input])]]=1.0\n",
    "        symbols_out_onehot=np.reshape(symbols_out_onehot,[1,-1])\n",
    "       \n",
    "        _,acc,loss,one_hot_pred=session.run([optimizer,accuracy,cost,pred],feed_dict={x:symbols_in_keys,y:symbols_out_onehot})\n",
    "        loss_total+=loss\n",
    "        acc_total+=acc\n",
    "        \n",
    "        if (step+1)%display_step==0:\n",
    "            print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\n",
    "                  \"{:.2f}%\".format(100*acc_total/display_step))\n",
    "            acc_total=0\n",
    "            loss_total=0\n",
    "            symbols_in=[training_data[i] for i in range(off_set,off_set+n_input)]\n",
    "            symbols_out=training_data[off_set+n_input]\n",
    "            symbols_out_pred=reverse_dictionary[int(tf.argmax(one_hot_pred,1).eval())]\n",
    "            print(\"%s - [%s] vs [%s]\" % (symbols_in,symbols_out,symbols_out_pred))\n",
    "        step+=1\n",
    "        off_set+=(n_input+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
